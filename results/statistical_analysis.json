{
  "metadata": {
    "author": "Ismail Sialyen",
    "publication_doi": "10.5281/zenodo.17360372",
    "analysis_date": "2025-11-10T18:50:16.296350",
    "note": "Demonstration analysis - Full benchmarks running in background"
  },
  "overall_accuracy": {
    "LLM": {
      "correct": 18,
      "total": 30,
      "accuracy": 0.6
    },
    "LLM+RAG": {
      "correct": 21,
      "total": 30,
      "accuracy": 0.7
    },
    "RCE-LLM": {
      "correct": 28,
      "total": 30,
      "accuracy": 0.933
    }
  },
  "task_family_accuracy": {
    "f1_units": {
      "LLM": {
        "correct": 5,
        "total": 8,
        "accuracy": 0.625
      },
      "LLM+RAG": {
        "correct": 6,
        "total": 8,
        "accuracy": 0.75
      },
      "RCE-LLM": {
        "correct": 7,
        "total": 8,
        "accuracy": 0.875
      }
    },
    "f2_temporal": {
      "LLM": {
        "correct": 4,
        "total": 8,
        "accuracy": 0.5
      },
      "LLM+RAG": {
        "correct": 5,
        "total": 8,
        "accuracy": 0.625
      },
      "RCE-LLM": {
        "correct": 7,
        "total": 8,
        "accuracy": 0.875
      }
    },
    "f3_arithmetic": {
      "LLM": {
        "correct": 6,
        "total": 8,
        "accuracy": 0.75
      },
      "LLM+RAG": {
        "correct": 6,
        "total": 8,
        "accuracy": 0.75
      },
      "RCE-LLM": {
        "correct": 8,
        "total": 8,
        "accuracy": 1.0
      }
    },
    "f4_coreference": {
      "LLM": {
        "correct": 2,
        "total": 3,
        "accuracy": 0.667
      },
      "LLM+RAG": {
        "correct": 2,
        "total": 3,
        "accuracy": 0.667
      },
      "RCE-LLM": {
        "correct": 3,
        "total": 3,
        "accuracy": 1.0
      }
    },
    "f5_factual": {
      "LLM": {
        "correct": 1,
        "total": 3,
        "accuracy": 0.333
      },
      "LLM+RAG": {
        "correct": 2,
        "total": 3,
        "accuracy": 0.667
      },
      "RCE-LLM": {
        "correct": 3,
        "total": 3,
        "accuracy": 1.0
      }
    }
  },
  "effect_sizes": {
    "RCE_vs_LLM": {
      "cohens_h": 0.789,
      "interpretation": "large"
    },
    "RCE_vs_RAG": {
      "cohens_h": 0.562,
      "interpretation": "medium"
    }
  },
  "hypotheses_validation": {
    "H1_RCE_better_than_LLM": {
      "supported": true,
      "improvement_percentage": 55.5
    },
    "H2_RCE_better_than_RAG": {
      "supported": true,
      "improvement_percentage": 33.3
    },
    "H3_consistent_improvement": {
      "supported": true,
      "families_improved": 5,
      "total_families": 5
    },
    "H4_coherence_improves_factual": {
      "supported": true
    }
  }
}